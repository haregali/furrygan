{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import functools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANLoss(nn.Module):\n",
    "    def __init__(self, use_lsgan, target_real_label=1.0, target_fake_label=0.0):\n",
    "        super(GANLoss, self).__init__()\n",
    "        self.use_lsgan = use_lsgan\n",
    "        self.target_real_label = target_real_label\n",
    "        self.target_fake_label = target_fake_label\n",
    "        self.real_label_var = None\n",
    "        self.fake_label_var = None\n",
    "        self.Tensor = tensor\n",
    "        \n",
    "        if self.use_lsgan:\n",
    "            self.loss = nn.MSELoss()\n",
    "        else:\n",
    "            self.loss = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "    def get_target_tensor(self, input, target_is_real):\n",
    "        target_tensor = None\n",
    "        if target_is_real:\n",
    "            create_label = ((self.real_label_var is None) or\n",
    "                            (self.real_label_var.numel() != input.numel()))\n",
    "            if create_label:\n",
    "                real_tensor = self.Tensor(input.size()).fill_(self.real_label)\n",
    "                self.real_label_var = Variable(real_tensor, requires_grad=False)\n",
    "            target_tensor = self.real_label_var\n",
    "        else:\n",
    "            create_label = ((self.fake_label_var is None) or\n",
    "                            (self.fake_label_var.numel() != input.numel()))\n",
    "            if create_label:\n",
    "                fake_tensor = self.Tensor(input.size()).fill_(self.fake_label)\n",
    "                self.fake_label_var = Variable(fake_tensor, requires_grad=False)\n",
    "            target_tensor = self.fake_label_var\n",
    "        return target_tensor\n",
    "    \n",
    "    def __call__(self, input, target_is_real):\n",
    "        if isinstance(input[0], list):\n",
    "            loss = 0\n",
    "            for input_i in input:\n",
    "                pred = input_i[-1]\n",
    "                target_tensor = self.get_target_tensor(pred, target_is_real)\n",
    "                loss += self.loss(pred, target_tensor)\n",
    "            return loss\n",
    "        else:            \n",
    "            target_tensor = self.get_target_tensor(input[-1], target_is_real)\n",
    "            return self.loss(input[-1], target_tensor)\n",
    "        \n",
    "class MFMLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MFMLoss, self).__init__()\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x_input, y_input):\n",
    "        loss = 0\n",
    "        for i in range(len(x_input)):\n",
    "            x = x_input[i][-2]\n",
    "            y = y_input[i][-2]\n",
    "            assert x.dim() == 4 \n",
    "            assert y.dim() == 4\n",
    "            x_mean = torch.mean(x,0)\n",
    "            y_mean = torch.mean(y,0)\n",
    "            loss += self.criterion(x_mean, y_mean.detach())\n",
    "        return loss   \n",
    "\n",
    "class Vgg19(torch.nn.Module):\n",
    "    def __init__(self, requires_grad=False):\n",
    "        super(Vgg19, self).__init__()\n",
    "        vgg_pretrained_features = models.vgg19(pretrained=True).features\n",
    "        self.slice1 = torch.nn.Sequential()\n",
    "        self.slice2 = torch.nn.Sequential()\n",
    "        self.slice3 = torch.nn.Sequential()\n",
    "        self.slice4 = torch.nn.Sequential()\n",
    "        self.slice5 = torch.nn.Sequential()\n",
    "        for x in range(2):\n",
    "            self.slice1.add_module(str(x), vgg_pretrained_features[x])\n",
    "        for x in range(2, 7):\n",
    "            self.slice2.add_module(str(x), vgg_pretrained_features[x])\n",
    "        for x in range(7, 12):\n",
    "            self.slice3.add_module(str(x), vgg_pretrained_features[x])\n",
    "        for x in range(12, 21):\n",
    "            self.slice4.add_module(str(x), vgg_pretrained_features[x])\n",
    "        for x in range(21, 30):\n",
    "            self.slice5.add_module(str(x), vgg_pretrained_features[x])\n",
    "        if not requires_grad:\n",
    "            for param in self.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, X, layers_num=5):\n",
    "        h_relu1 = self.slice1(X)\n",
    "        if layers_num == 1:\n",
    "            return [h_relu1]   \n",
    "        h_relu2 = self.slice2(h_relu1)     \n",
    "        if layers_num == 2:\n",
    "            return [h_relu1, h_relu2]   \n",
    "        h_relu3 = self.slice3(h_relu2)   \n",
    "        if layers_num == 3:\n",
    "            return [h_relu1, h_relu2, h_relu3]     \n",
    "        h_relu4 = self.slice4(h_relu3)        \n",
    "        if layers_num == 4:\n",
    "            return [h_relu1, h_relu2, h_relu3, h_relu4]     \n",
    "        h_relu5 = self.slice5(h_relu4)                \n",
    "        out = [h_relu1, h_relu2, h_relu3, h_relu4, h_relu5]\n",
    "        return out\n",
    "\n",
    "class VGGLoss(nn.Module):\n",
    "    def __init__(self, weights = None):\n",
    "        super(VGGLoss, self).__init__()       \n",
    "        if weights != None: \n",
    "            self.weights = weights\n",
    "        else:\n",
    "            self.weights = [1.0/4, 1.0/4, 1.0/4, 1.0/8, 1.0/8]        \n",
    "        self.vgg = Vgg19()\n",
    "        self.criterion = nn.L1Loss()\n",
    "\n",
    "    def forward(self, x, y, face_mask, mask_weights):              \n",
    "        assert face_mask.size()[1] == len(mask_weights)  # suppose to be 5\n",
    "        x_vgg, y_vgg = self.vgg(x,layers_num=len(self.weights)), self.vgg(y,layers_num=len(self.weights))\n",
    "        mask = []\n",
    "        mask.append(face_mask.detach())\n",
    "        \n",
    "        downsample = nn.MaxPool2d(2)\n",
    "        for i in range(len(x_vgg)):\n",
    "            mask.append(downsample(mask[i]))\n",
    "            mask[i] = mask[i].detach()\n",
    "        loss = 0\n",
    "        for i in range(len(x_vgg)):\n",
    "            for mask_index in range(len(mask_weights)):\n",
    "                a = x_vgg[i]*mask[i][:,mask_index:mask_index+1,:,:]\n",
    "                loss += self.weights[i] * self.criterion(x_vgg[i]*mask[i][:,mask_index:mask_index+1,:,:], (y_vgg[i]*mask[i][:,mask_index:mask_index+1,:,:]).detach()) * mask_weights[mask_index]\n",
    "        return loss    \n",
    "\n",
    "class GramMatrixLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GramMatrixLoss, self).__init__()        \n",
    "        self.weights = [1.0,1.0,1.0]\n",
    "        self.vgg = Vgg19()\n",
    "        # self.criterion = nn.L1Loss()\n",
    "        self.criterion = nn.MSELoss()\n",
    "        # self.weights = [1.0/32, 1.0/16, 1.0/8, 1.0/4, 1.0]        \n",
    "\n",
    "    def forward(self, x, y, label):\n",
    "        # we use this label to label face\n",
    "        face_mask = (label==1).type(torch.FloatTensor)\n",
    "        mask = []\n",
    "        mask.append(face_mask)\n",
    "        x_vgg, y_vgg = self.vgg(x,layers_num=len(self.weights)), self.vgg(y,layers_num=len(self.weights))\n",
    "        downsample = nn.MaxPool2d(2)\n",
    "        for i in range(len(x_vgg)):\n",
    "            mask.append(downsample(mask[i]))\n",
    "            mask[i] = mask[i].detach()\n",
    "        loss = 0\n",
    "        for i in range(len(x_vgg)):\n",
    "            loss += self.weights[i] * self.criterion(grammatrix(x_vgg[i]*mask[i]), grammatrix(y_vgg[i]*mask[i]).detach())\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, dim, padding_type, norm_layer, activation=nn.ReLU(True), use_dropout=False):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, activation, use_dropout)\n",
    "\n",
    "    def build_conv_block(self, dim, padding_type, norm_layer, activation, use_dropout):\n",
    "        conv_block = []\n",
    "        p = 0\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "        else:\n",
    "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
    "\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p),\n",
    "                       norm_layer(dim),\n",
    "                       activation]\n",
    "        if use_dropout:\n",
    "            conv_block += [nn.Dropout(0.5)]\n",
    "\n",
    "        p = 0\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "        else:\n",
    "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p),\n",
    "                       norm_layer(dim)]\n",
    "\n",
    "        return nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x + self.conv_block(x)\n",
    "        return out\n",
    "\n",
    "class GeneratorNetwork(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, ngf):\n",
    "        self.input_nc = input_nc\n",
    "        self.output_nc = output_nc\n",
    "        self.ngf = 64\n",
    "        self.norm_type = 'batch'\n",
    "        self.n_downsample = 2\n",
    "        self.n_blocks_global = 9\n",
    "        self.n_local_enhancers = 1\n",
    "        self.n_blocks_local = 3\n",
    "        self.embed_nc = 256*5\n",
    "        self.padding_type='reflect'\n",
    "\n",
    "        super(EmbedGlobalBGGenerator, self).__init__()\n",
    "        norm_layer = get_norm_layer(norm_type=self.norm_type)\n",
    "        activation = nn.ReLU(True)\n",
    "        \n",
    "        downsample_model = [nn.ReflectionPad2d(3), nn.Conv2d(self.input_nc, self.ngf, kernel_size=7, padding=0), norm_layer(self.ngf), activation]\n",
    "        \n",
    "        for i in range(self.n_downsample):\n",
    "            mult = 2**i\n",
    "            if i != self.n_downsample-1:\n",
    "                downsample_model += [nn.Conv2d(self.ngf * mult, self.ngf * mult * 2, kernel_size=3, stride=2, padding=1),\n",
    "                      norm_layer(self.ngf * mult * 2), activation]\n",
    "            else:\n",
    "                downsample_model += [nn.Conv2d(self.ngf * mult, self.ngf * mult * 2, kernel_size=3, stride=2, padding=1),\n",
    "                      norm_layer(self.ngf * mult * 2), activation]\n",
    "        self.downsample_model = nn.Sequential(*downsample_model)\n",
    "        \n",
    "        model=[]\n",
    "        model += [nn.Conv2d(in_channels=self.ngf*(2**self.n_downsample)+self.embed_nc, out_channels=self.ngf*(2**self.n_downsample), kernel_size=1, padding=0, stride=1, bias=True)]\n",
    "\n",
    "        mult = 2**self.n_downsample\n",
    "        for i in range(self.n_blocks_global):\n",
    "            model += [ResnetBlock(self.ngf * mult, padding_type=self.padding_type, activation=activation, norm_layer=norm_layer)]\n",
    "        \n",
    "        ### upsample         \n",
    "        for i in range(self.n_downsample):\n",
    "            mult = 2**(self.n_downsample - i)\n",
    "            model += [nn.ConvTranspose2d(self.ngf * mult, int(self.ngf * mult / 2), kernel_size=4, stride=2, padding=1, output_padding=0),\n",
    "                       norm_layer(int(self.ngf * mult / 2)), activation]\n",
    "        \n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "        bg_encoder = [nn.ReflectionPad2d(3), nn.Conv2d(3, self.ngf, kernel_size=7, padding=0), norm_layer(self.ngf), activation]\n",
    "        self.bg_encoder = nn.Sequential(*bg_encoder)\n",
    "\n",
    "        bg_decoder = [nn.Conv2d(in_channels=ngf*2, out_channels=self.ngf, kernel_size=1, padding=0, stride=1, bias=True)]\n",
    "        bg_decoder += [nn.ReflectionPad2d(3), nn.Conv2d(self.ngf, output_nc, kernel_size=7, padding=0), nn.Tanh()]\n",
    "        self.bg_decoder = nn.Sequential(*bg_decoder)\n",
    "        \n",
    "    def forward(self, input, type=\"label_encoder\"):\n",
    "        if type==\"label_encoder\":\n",
    "            return self.downsample_model(input)\n",
    "        elif type==\"image_G\":\n",
    "            return self.model(input)\n",
    "        elif type==\"bg_encoder\":\n",
    "            return self.bg_encoder(input)\n",
    "        elif type==\"bg_decoder\":\n",
    "            # notice before bg_decoder, we should concate the feature map form G and bg_encoder\n",
    "            return self.bg_decoder(input)\n",
    "        else:\n",
    "            print(\"wrong type in generator network - forward \")\n",
    "\n",
    "class NLayerDiscriminator(nn.Module):\n",
    "    def __init__(self, input_nc, ndf, dis_n_layers, norm_layer, use_sigoid, getIntermFeat):\n",
    "        super(NLayerDiscriminator, self).__init__()\n",
    "        self.input_nc = input_nc\n",
    "        self.ndf = ndf\n",
    "        self.dis_n_layers = dis_n_layers\n",
    "        self.norm_layer = norm_layer\n",
    "        self.use_sigoid = use_sigoid\n",
    "        self.getIntermFeat = getIntermFeat\n",
    "        \n",
    "        kw = 4\n",
    "        padw = int(np.ceil((kw-1.0)/2))\n",
    "        sequence = [[nn.Conv2d(self.input_nc, self.ndf, kernel_size=kw, stride=2, padding=padw), nn.LeakyReLU(0.2, True)]]\n",
    "\n",
    "        nf = self.ndf\n",
    "        for n in range(1, self.dis_n_layers):\n",
    "            nf_prev = nf\n",
    "            nf = min(nf * 2, 512)\n",
    "            sequence += [[\n",
    "                nn.Conv2d(nf_prev, nf, kernel_size=kw, stride=2, padding=padw),\n",
    "                norm_layer(nf), nn.LeakyReLU(0.2, True)\n",
    "            ]]\n",
    "\n",
    "        nf_prev = nf\n",
    "        nf = min(nf * 2, 512)\n",
    "        sequence += [[\n",
    "            nn.Conv2d(nf_prev, nf, kernel_size=kw, stride=1, padding=padw),\n",
    "            norm_layer(nf),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]]\n",
    "\n",
    "        sequence += [[nn.Conv2d(nf, 1, kernel_size=kw, stride=1, padding=padw)]]\n",
    "\n",
    "        if self.use_sigmoid:\n",
    "            sequence += [[nn.Sigmoid()]]\n",
    "\n",
    "        if self.getIntermFeat:\n",
    "            for n in range(len(sequence)):\n",
    "                setattr(self, 'model'+str(n), nn.Sequential(*sequence[n]))\n",
    "        else:\n",
    "            sequence_stream = []\n",
    "            for n in range(len(sequence)):\n",
    "                sequence_stream += sequence[n]\n",
    "            self.model = nn.Sequential(*sequence_stream)\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.getIntermFeat:\n",
    "            # res = [input]\n",
    "            # for n in range(self.n_layers+2):\n",
    "            #     model = getattr(self, 'model'+str(n))\n",
    "            #     res.append(model(res[-1]))\n",
    "            # return res[1:]\n",
    "            res = [input]\n",
    "            for n in range(self.dis_n_layers+2):\n",
    "                model = getattr(self, 'model'+str(n))\n",
    "                res.append(model(res[-1]))\n",
    "            print(\"debug in networks line 721 ----\")\n",
    "            print(len(res[-2:]))\n",
    "            return res[-2:]\n",
    "        else:\n",
    "            return self.model(input)\n",
    "        \n",
    "        \n",
    "class DiscriminatorNetwork(nn.Module):\n",
    "    def __init__(self, input_nc, dis_n_layers, numD, use_sigmoid):\n",
    "        super(DiscriminatorNetwork, self).__init__()\n",
    "        self.input_nc = input_nc\n",
    "        self.dis_n_layers = dis_n_layers\n",
    "        self.num_D = num_D\n",
    "        self.use_sigmoid = use_sigmoid\n",
    "        self.ndf = 64\n",
    "        self.norm_type = 'batch'\n",
    "        self.getIntermFeat = True\n",
    "        \n",
    "        norm_layer = get_norm_layer(norm_type=self.norm_type)\n",
    " \n",
    "        for i in range(self.num_D):\n",
    "            netD = NLayerDiscriminator(self.input_nc, self.ndf, self.dis_n_layers, norm_layer, self.use_sigmoid, self.getIntermFeat)\n",
    "            if self.getIntermFeat:                                \n",
    "                for j in range(self.dis_n_layers+2):\n",
    "                    setattr(self, 'scale'+str(i)+'_layer'+str(j), getattr(netD, 'model'+str(j)))                                   \n",
    "            else:\n",
    "                setattr(self, 'layer'+str(i), netD.model)\n",
    "\n",
    "        self.downsample = nn.AvgPool2d(3, stride=2, padding=[1, 1], count_include_pad=False)\n",
    "    \n",
    "    def singleD_forward(self, model, input):\n",
    "        if self.getIntermFeat:\n",
    "            result = [input]\n",
    "            for i in range(len(model)):\n",
    "                result.append(model[i](result[-1]))\n",
    "            return result[-2:]\n",
    "        else:\n",
    "            return [model(input)]\n",
    "        \n",
    "    def forward(self, input):        \n",
    "        num_D = self.num_D\n",
    "        result = []\n",
    "        input_downsampled = input\n",
    "        for i in range(num_D):\n",
    "            if self.getIntermFeat:\n",
    "                model = [getattr(self, 'scale'+str(num_D-1-i)+'_layer'+str(j)) for j in range(self.dis_n_layers+2)]\n",
    "            else:\n",
    "                model = getattr(self, 'layer'+str(num_D-1-i))\n",
    "            # print(\"i is \")\n",
    "            # print(i)\n",
    "            # print(\"input_downsampled size is \")\n",
    "            # print(input_downsampled.size())\n",
    "            \n",
    "            result.append(self.singleD_forward(model, input_downsampled))\n",
    "            if i != (num_D-1):\n",
    "                input_downsampled = self.downsample(input_downsampled)\n",
    "        return result\n",
    "\n",
    "class UnetSkipConnectionBlock(nn.Module):\n",
    "    def __init__(self, outer_nc, inner_nc, input_nc=None,\n",
    "                 submodule=None, outermost=False, innermost=False, norm_layer=nn.BatchNorm2d, use_dropout=False):\n",
    "        super(UnetSkipConnectionBlock, self).__init__()\n",
    "        self.outermost = outermost\n",
    "        if type(norm_layer) == functools.partial:\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "        if input_nc is None:\n",
    "            input_nc = outer_nc\n",
    "        downconv = nn.Conv2d(input_nc, inner_nc, kernel_size=4,\n",
    "                             stride=2, padding=1, bias=use_bias)\n",
    "        downrelu = nn.LeakyReLU(0.2, True)\n",
    "        downnorm = norm_layer(inner_nc)\n",
    "        uprelu = nn.ReLU(True)\n",
    "        upnorm = norm_layer(outer_nc)\n",
    "        \n",
    "        global printlayer_index\n",
    "        \n",
    "        if outermost:\n",
    "            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc,\n",
    "                                        kernel_size=4, stride=2,\n",
    "                                        padding=1,output_padding=1)\n",
    "            down = [downconv]\n",
    "            up = [uprelu, upconv, nn.Tanh()]\n",
    "            # printlayer = [PrintLayer(name = str(printlayer_index))]\n",
    "            # printlayer_index += 1\n",
    "            # model = printlayer + down + [submodule] + up\n",
    "            model = down + [submodule] + up\n",
    "        elif innermost:\n",
    "            upconv = nn.ConvTranspose2d(inner_nc, outer_nc,\n",
    "                                        kernel_size=4, stride=2,\n",
    "                                        padding=1, bias=use_bias,output_padding=1)\n",
    "            # printlayer = [PrintLayer(str(printlayer_index))]\n",
    "            # printlayer_index += 1\n",
    "            down = [downrelu, downconv]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "            # model = printlayer + down + up\n",
    "            model = down + up\n",
    "        else:\n",
    "            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc,\n",
    "                                        kernel_size=4, stride=2,\n",
    "                                        padding=1, bias=use_bias,output_padding=1)\n",
    "            down = [downrelu, downconv, downnorm]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "            # printlayer = [PrintLayer(str(printlayer_index))]\n",
    "            # printlayer_index += 1\n",
    "            if use_dropout:\n",
    "                model = down + [submodule] + up + [nn.Dropout(0.5)]\n",
    "                # model = printlayer + down + [submodule] + printlayer + up + [nn.Dropout(0.5)]\n",
    "            else:\n",
    "                model = down + [submodule]  + up\n",
    "                # model = printlayer + down + [submodule] + printlayer + up\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        model_output = self.model(x)\n",
    "        wb,hb = model_output.size()[3],model_output.size()[2]\n",
    "        wa,ha = x.size()[3],x.size()[2]\n",
    "        l = int((wb-wa)/2)\n",
    "        t = int((hb-ha)/2)\n",
    "        model_output = model_output[:,:,t:t+ha,l:l+wa]\n",
    "        if self.outermost:\n",
    "            return model_output\n",
    "        else:\n",
    "            return torch.cat([x, model_output], 1)           #if not the outermost block, we concate x and self.model(x) during forward to implement unet\n",
    "    \n",
    "class UnetGenerator(nn.Module):\n",
    "    def __init__(self, segment_classes, input_nc, num_downs, ngf=64,\n",
    "                 norm_layer=nn.BatchNorm2d, use_dropout=False):\n",
    "        super(UnetGenerator, self).__init__()\n",
    "        output_nc = segment_classes\n",
    "        # construct unet structure\n",
    "        unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=None, norm_layer=norm_layer, innermost=True)\n",
    "        for i in range(num_downs - 5):\n",
    "            unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer, use_dropout=use_dropout)\n",
    "        unet_block = UnetSkipConnectionBlock(ngf * 4, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
    "        unet_block = UnetSkipConnectionBlock(ngf * 2, ngf * 4, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
    "        unet_block = UnetSkipConnectionBlock(ngf, ngf * 2, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
    "        unet_block = UnetSkipConnectionBlock(output_nc, ngf, input_nc=input_nc, submodule=unet_block, outermost=True, norm_layer=norm_layer)\n",
    "        #maybe do some check here with softmax\n",
    "        self.model = unet_block\n",
    "\n",
    "    def forward(self, input):\n",
    "        softmax = torch.nn.Softmax(dim = 1)\n",
    "        return softmax(self.model(input))    \n",
    "\n",
    "class PNetwork(nn.Module):\n",
    "    def __init__(self, label_nc, output_nc):\n",
    "        self.label_nc = label_nc\n",
    "        self.output_nc = output_nc\n",
    "        self.ngf = 64\n",
    "        self.norm_type = 'batch'\n",
    "        self.use_dropout = True\n",
    "        norm_layer = get_norm_layer(norm_type=norm)\n",
    "        \n",
    "        netP = UnetGenerator(self.label_nc, self.input_nc, 6, self.ngf, norm_layer=norm_layer, use_dropout=self.use_dropout)\n",
    "\n",
    "        \n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, channel_in, channel_out, kernel_size=7, padding=3, stride=4):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        # convolution to halve the dimensions\n",
    "        self.conv = nn.Conv2d(in_channels=channel_in, out_channels=channel_out, kernel_size=kernel_size, padding=padding, stride=stride)\n",
    "        self.bn = nn.BatchNorm2d(num_features=channel_out, momentum=0.9)\n",
    "        self.relu = nn.ReLU(True)\n",
    "\n",
    "    def forward(self, ten, out=False,t = False):\n",
    "        # here we want to be able to take an intermediate output for reconstruction error\n",
    "        if out:\n",
    "            ten = self.conv(ten)\n",
    "            ten_out = ten\n",
    "            ten = self.bn(ten)\n",
    "            ten = self.relu(ten)\n",
    "            return ten, ten_out\n",
    "        else:\n",
    "            ten = self.conv(ten)\n",
    "            ten = self.bn(ten)\n",
    "            ten = self.relu(ten)\n",
    "            return ten\n",
    "        \n",
    "class  EncoderGenerator_mask_skin(nn.Module):\n",
    "    \"\"\"docstring for  EncoderGenerator\"\"\"\n",
    "    def __init__(self, norm_layer):\n",
    "        super( EncoderGenerator_mask_skin, self).__init__()\n",
    "        layers_list = []\n",
    "        \n",
    "        # 3*256*256\n",
    "        layers_list.append(EncoderBlock(channel_in=3, channel_out=64, kernel_size=4, padding=1, stride=2))  # 64*128*128\n",
    "        layers_list.append(EncoderBlock(channel_in=64, channel_out=128, kernel_size=4, padding=1, stride=2))  # 128*64*64\n",
    "        layers_list.append(EncoderBlock(channel_in=128, channel_out=256, kernel_size=4, padding=1, stride=2))  # 128*32*32\n",
    "        layers_list.append(EncoderBlock(channel_in=256, channel_out=512, kernel_size=4, padding=1, stride=2))  # 128*16*16\n",
    "        layers_list.append(EncoderBlock(channel_in=512, channel_out=512, kernel_size=4, padding=1, stride=2))  # 128*8*8\n",
    "        layers_list.append(EncoderBlock(channel_in=512, channel_out=512, kernel_size=4, padding=1, stride=2))  # 512*4*4\n",
    "        layers_list.append(EncoderBlock(channel_in=512, channel_out=512, kernel_size=4, padding=1, stride=2))  # 512*2*2\n",
    "        # final shape Bx128*4*4\n",
    "        self.conv = nn.Sequential(*layers_list)\n",
    "\n",
    "        # self.c_mu = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=1, padding=0, stride=1)\n",
    "        # self.c_var = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=1, padding=0, stride=1)\n",
    "        self.fc_mu = nn.Sequential(nn.Linear(in_features=512*2*2, out_features=1024),\n",
    "                                # nn.BatchNorm1d(num_features=1024,momentum=0.9),\n",
    "                                nn.ReLU(True),\n",
    "                                nn.Linear(in_features=1024, out_features=512))\n",
    "        self.fc_var = nn.Sequential(nn.Linear(in_features=512*2*2, out_features=1024),\n",
    "                                # nn.BatchNorm1d(num_features=1024,momentum=0.9),\n",
    "                                nn.ReLU(True),\n",
    "                                nn.Linear(in_features=1024, out_features=512))\n",
    "\n",
    "    def forward(self, ten):\n",
    "        ten = self.conv(ten)\n",
    "        ten = ten.view(ten.size()[0],-1)\n",
    "        mu = self.fc_mu(ten)\n",
    "        logvar = self.fc_var(ten)\n",
    "        return mu,logvar\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return super(EncoderGenerator_mask_skin, self).__call__(*args, **kwargs)\n",
    "    \n",
    "class  EncoderGenerator_mask_mouth(nn.Module):\n",
    "    \"\"\"docstring for  EncoderGenerator\"\"\"\n",
    "    def __init__(self, norm_layer):\n",
    "        super( EncoderGenerator_mask_mouth, self).__init__()\n",
    "        layers_list = []\n",
    "        \n",
    "        # 3*80*144\n",
    "        layers_list.append(EncoderBlock(channel_in=3, channel_out=64, kernel_size=4, padding=1, stride=2))  # 40*72\n",
    "        layers_list.append(EncoderBlock(channel_in=64, channel_out=128, kernel_size=4, padding=1, stride=2))  # 20*36\n",
    "        layers_list.append(EncoderBlock(channel_in=128, channel_out=256, kernel_size=4, padding=1, stride=2))  # 10*18\n",
    "        layers_list.append(EncoderBlock(channel_in=256, channel_out=512, kernel_size=4, padding=1, stride=2))  # 5*9\n",
    "        # layers_list.append(EncoderBlock(channel_in=512, channel_out=512, kernel_size=4, padding=1, stride=2))  # 3*5\n",
    "        \n",
    "        # final shape Bx256*7*6\n",
    "        self.conv = nn.Sequential(*layers_list)\n",
    "        self.fc_mu = nn.Sequential(nn.Linear(in_features=512*5*9, out_features=1024),\n",
    "                                # nn.BatchNorm1d(num_features=1024,momentum=0.9),\n",
    "                                nn.ReLU(True),\n",
    "                                nn.Linear(in_features=1024, out_features=512))\n",
    "        self.fc_var = nn.Sequential(nn.Linear(in_features=512*5*9, out_features=1024),\n",
    "                                # nn.BatchNorm1d(num_features=1024,momentum=0.9),\n",
    "                                nn.ReLU(True),\n",
    "                                nn.Linear(in_features=1024, out_features=512))\n",
    "        # self.c_mu = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=1, padding=0, stride=1)\n",
    "        # self.c_var = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=1, padding=0, stride=1)\n",
    "\n",
    "\n",
    "    def forward(self, ten):\n",
    "        ten = self.conv(ten)\n",
    "        ten = ten.view(ten.size()[0],-1)\n",
    "        mu = self.fc_mu(ten)\n",
    "        logvar = self.fc_var(ten)\n",
    "        return mu,logvar\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return super(EncoderGenerator_mask_mouth, self).__call__(*args, **kwargs)\n",
    "\n",
    "class  EncoderGenerator_mask_eye(nn.Module):\n",
    "    \"\"\"docstring for  EncoderGenerator\"\"\"\n",
    "    def __init__(self, norm_layer):\n",
    "        super( EncoderGenerator_mask_eye, self).__init__()\n",
    "        layers_list = []\n",
    "        \n",
    "        # 3*32*48\n",
    "        layers_list.append(EncoderBlock(channel_in=3, channel_out=64, kernel_size=4, padding=1, stride=2))  # 16*24\n",
    "        layers_list.append(EncoderBlock(channel_in=64, channel_out=128, kernel_size=4, padding=1, stride=2))  # \n",
    "        layers_list.append(EncoderBlock(channel_in=128, channel_out=256, kernel_size=4, padding=1, stride=2))  # 4*6\n",
    "        layers_list.append(EncoderBlock(channel_in=256, channel_out=512, kernel_size=4, padding=1, stride=2))  # 512*2*3\n",
    "        \n",
    "        # final shape Bx256*7*6\n",
    "        self.conv = nn.Sequential(*layers_list)\n",
    "        self.fc_mu = nn.Sequential(nn.Linear(in_features=512*2*3, out_features=1024),\n",
    "                                # nn.BatchNorm1d(num_features=1024,momentum=0.9),\n",
    "                                nn.ReLU(True),\n",
    "                                nn.Linear(in_features=1024, out_features=512))\n",
    "        self.fc_var = nn.Sequential(nn.Linear(in_features=512*2*3, out_features=1024),\n",
    "                                # nn.BatchNorm1d(num_features=1024,momentum=0.9),\n",
    "                                nn.ReLU(True),\n",
    "                                nn.Linear(in_features=1024, out_features=512))\n",
    "        # self.c_mu = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=1, padding=0, stride=1)\n",
    "        # self.c_var = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=1, padding=0, stride=1)\n",
    "\n",
    "\n",
    "    def forward(self, ten):\n",
    "        ten = self.conv(ten)\n",
    "        ten = ten.view(ten.size()[0],-1)\n",
    "        mu = self.fc_mu(ten)\n",
    "        logvar = self.fc_var(ten)\n",
    "        return mu,logvar\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return super(EncoderGenerator_mask_eye, self).__call__(*args, **kwargs)\n",
    "    \n",
    "        \n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, channel_in, channel_out, kernel_size=4, padding=1, stride=2, output_padding=0, norelu=False):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        # transpose convolution to double the dimensions\n",
    "        # self.conv = nn.ConvTranspose2d(channel_in, channel_out, kernel_size=kernel_size, padding=padding, stride=stride, output_padding=output_padding)\n",
    "        # self.bn = nn.BatchNorm2d(channel_out, momentum=0.9)\n",
    "        # self.bn = nn.InstanceNorm2d(channel_out, momentum=0.9,track_running_stats=True)\n",
    "        layers_list = []\n",
    "        layers_list.append(nn.ConvTranspose2d(channel_in, channel_out, kernel_size=kernel_size, padding=padding, stride=stride, output_padding=output_padding))\n",
    "        layers_list.append(nn.BatchNorm2d(channel_out, momentum=0.9))\n",
    "        if norelu == False:\n",
    "            layers_list.append(nn.ReLU(True))\n",
    "        self.conv = nn.Sequential(*layers_list)\n",
    "\n",
    "    def forward(self, ten):\n",
    "        ten = self.conv(ten)\n",
    "        return ten\n",
    "\n",
    "class DecoderGenerator_mask_skin_image(nn.Module):\n",
    "    def __init__(self, norm_layer):  \n",
    "        super(DecoderGenerator_mask_skin_image, self).__init__()\n",
    "        self.fc = nn.Sequential(nn.Linear(in_features=512, out_features=512*2*2))\n",
    "        # input is 512*2*2\n",
    "        layers_list = []\n",
    "        layers_list.append(DecoderBlock(channel_in=512, channel_out=512, kernel_size=4, padding=1, stride=2, output_padding=0))  #128*4\n",
    "        layers_list.append(DecoderBlock(channel_in=512, channel_out=512, kernel_size=4, padding=1, stride=2, output_padding=0))  #128*8*8\n",
    "        layers_list.append(DecoderBlock(channel_in=512, channel_out=512, kernel_size=4, padding=1, stride=2, output_padding=0))  #128*16*16\n",
    "        layers_list.append(DecoderBlock(channel_in=512, channel_out=512, kernel_size=4, padding=1, stride=2, output_padding=0))  #128*32*32\n",
    "        layers_list.append(DecoderBlock(channel_in=512, channel_out=256, kernel_size=4, padding=1, stride=2, output_padding=0))  #128*64*64\n",
    "        layers_list.append(DecoderBlock(channel_in=256, channel_out=128, kernel_size=4, padding=1, stride=2, output_padding=0))  #64*128*128\n",
    "        layers_list.append(DecoderBlock(channel_in=128, channel_out=64, kernel_size=4, padding=1, stride=2, output_padding=0))  #64*256*256\n",
    "        layers_list.append(nn.ReflectionPad2d(2))\n",
    "        layers_list.append(nn.Conv2d(64,3,kernel_size=5,padding=0))\n",
    "        layers_list.append(nn.Tanh())\n",
    "        \n",
    "        self.conv = nn.Sequential(*layers_list)\n",
    "\n",
    "    def forward(self, ten):\n",
    "        # print(\"in DecoderGenerator_mask_skin, print some shape \")\n",
    "        ten = self.fc(ten)\n",
    "        ten = ten.view(ten.size()[0],512, 2, 2)\n",
    "        ten = self.conv(ten)\n",
    "        assert ten.size()[1] == 3\n",
    "        assert ten.size()[2] == 256\n",
    "        assert ten.size()[3] == 256\n",
    "        return ten\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return super(DecoderGenerator_mask_skin_image, self).__call__(*args, **kwargs)\n",
    "    \n",
    "class DecoderGenerator_mask_mouth_image(nn.Module):\n",
    "    def __init__(self, norm_layer):  \n",
    "        super(DecoderGenerator_mask_mouth_image, self).__init__()\n",
    "        # start from B*1024\n",
    "        # self.fc = nn.Sequential(nn.Linear(in_features=1024, out_features=512*4*4),\n",
    "        #                         nn.BatchNorm1d(num_features=512*4*4, momentum=0.9),\n",
    "        #                         nn.ReLU(True))\n",
    "        self.fc = nn.Sequential(nn.Linear(in_features=512, out_features=512*5*9))\n",
    "        layers_list = []\n",
    "        # layers_list.append(nn.BatchNorm2d(256, momentum=0.9))\n",
    "        # layers_list.append(nn.ReLU(True))\n",
    "\n",
    "        layers_list.append(DecoderBlock(channel_in=512, channel_out=256, kernel_size=4, padding=1, stride=2, output_padding=0)) #10*18\n",
    "        layers_list.append(DecoderBlock(channel_in=256, channel_out=128, kernel_size=4, padding=1, stride=2, output_padding=0)) #20*36\n",
    "        layers_list.append(DecoderBlock(channel_in=128, channel_out=64, kernel_size=4, padding=1, stride=2, output_padding=0)) #40*72\n",
    "        layers_list.append(DecoderBlock(channel_in=64, channel_out=64, kernel_size=4, padding=1, stride=2, output_padding=0)) #80*144\n",
    "        # layers_list.append(DecoderBlock(channel_in=64, channel_out=64, kernel_size=4, padding=1, stride=2, output_padding=0)) #96*160\n",
    "        layers_list.append(nn.ReflectionPad2d(2))\n",
    "        layers_list.append(nn.Conv2d(64,3,kernel_size=5,padding=0))\n",
    "        layers_list.append(nn.Tanh())\n",
    "\n",
    "        # layers_list.append(DecoderBlock(channel_in=256, channel_out=256, kernel_size=3, padding=1, stride=1, output_padding=0)) #256*12*14\n",
    "\n",
    "        self.conv = nn.Sequential(*layers_list)\n",
    "\n",
    "    def forward(self, ten):\n",
    "        # print(\"in DecoderGenerator, print some shape \")\n",
    "        ten = self.fc(ten)\n",
    "        ten = ten.view(ten.size()[0],512, 5, 9)\n",
    "        ten = self.conv(ten)\n",
    "        assert ten.size()[1] == 3\n",
    "        assert ten.size()[2] == 80\n",
    "        assert ten.size()[3] == 144\n",
    "        return ten\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return super(DecoderGenerator_mask_mouth_image, self).__call__(*args, **kwargs)\n",
    "\n",
    "\n",
    "class DecoderGenerator_mask_eye_image(nn.Module):\n",
    "    def __init__(self, norm_layer):  \n",
    "        super(DecoderGenerator_mask_eye_image, self).__init__()\n",
    "        # start from B*1024\n",
    "        # self.fc = nn.Sequential(nn.Linear(in_features=1024, out_features=512*4*4),\n",
    "        #                         nn.BatchNorm1d(num_features=512*4*4, momentum=0.9),\n",
    "        #                         nn.ReLU(True))\n",
    "        self.fc = nn.Sequential(nn.Linear(in_features=512, out_features=512*2*3, bias=False))\n",
    "        layers_list = []\n",
    "        # layers_list.append(nn.BatchNorm2d(256, momentum=0.9))\n",
    "        # layers_list.append(nn.ReLU(True))\n",
    "\n",
    "        layers_list.append(DecoderBlock(channel_in=512, channel_out=256, kernel_size=4, padding=1, stride=2, output_padding=0)) #256*4\n",
    "        layers_list.append(DecoderBlock(channel_in=256, channel_out=128, kernel_size=4, padding=1, stride=2, output_padding=0)) #128*8\n",
    "        layers_list.append(DecoderBlock(channel_in=128, channel_out=64, kernel_size=4, padding=1, stride=2, output_padding=0)) #64*16\n",
    "        layers_list.append(DecoderBlock(channel_in=64, channel_out=64, kernel_size=4, padding=1, stride=2, output_padding=0)) #64*32\n",
    "        # layers_list.append(DecoderBlock(channel_in=64, channel_out=64, kernel_size=4, padding=1, stride=2, output_padding=0)) #64*64\n",
    "        layers_list.append(nn.ReflectionPad2d(2))\n",
    "        layers_list.append(nn.Conv2d(64,3,kernel_size=5,padding=0))\n",
    "        layers_list.append(nn.Tanh())\n",
    "\n",
    "        # layers_list.append(DecoderBlock(channel_in=256, channel_out=256, kernel_size=3, padding=1, stride=1, output_padding=0)) #256*12*14\n",
    "\n",
    "        self.conv = nn.Sequential(*layers_list)\n",
    "\n",
    "    def forward(self, ten):\n",
    "        # print(\"in DecoderGenerator, print some shape \")\n",
    "        ten = self.fc(ten)\n",
    "        ten = ten.view(ten.size()[0],512, 2, 3)\n",
    "        ten = self.conv(ten)\n",
    "        assert ten.size()[1] == 3\n",
    "        assert ten.size()[2] == 32\n",
    "        assert ten.size()[3] == 48\n",
    "        return ten\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return super(DecoderGenerator_mask_eye_image, self).__call__(*args, **kwargs)\n",
    "\n",
    "\n",
    "class DecoderGenerator_mask_mouth(nn.Module):\n",
    "    def __init__(self, norm_layer):  \n",
    "        super(DecoderGenerator_mask_mouth, self).__init__()\n",
    "        \n",
    "\n",
    "        self.fc = nn.Sequential(nn.Linear(in_features=512, out_features=512*5*9))\n",
    "        layers_list = []\n",
    "\n",
    "        layers_list.append(DecoderBlock(channel_in=512, channel_out=256, kernel_size=4, padding=1, stride=2)) #10*18\n",
    "        layers_list.append(DecoderBlock(channel_in=256, channel_out=256, kernel_size=4, padding=1, stride=2)) #20*36\n",
    "        # layers_list.append(DecoderBlock(channel_in=256, channel_out=256, kernel_size=4, padding=1, stride=2)) #40*72\n",
    "\n",
    "        self.conv = nn.Sequential(*layers_list)\n",
    "\n",
    "    def forward(self, ten):\n",
    "        # print(\"in DecoderGenerator, print some shape \")\n",
    "        # ten = self.fc(ten)\n",
    "        # ten = ten.view(ten.size()[0],512, 4, 4)\n",
    "        ten = self.fc(ten)\n",
    "        ten = ten.view(ten.size()[0],512, 5, 9)\n",
    "        ten = self.conv(ten)\n",
    "        assert ten.size()[1] == 256\n",
    "        assert ten.size()[2] == 20\n",
    "        assert ten.size()[3] == 36\n",
    "        return ten\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return super(DecoderGenerator_mask_mouth, self).__call__(*args, **kwargs)\n",
    "\n",
    "\n",
    "class DecoderGenerator_mask_eye(nn.Module):\n",
    "    def __init__(self, norm_layer):  \n",
    "        super(DecoderGenerator_mask_eye, self).__init__()\n",
    "        # start from B*1024\n",
    "        # self.fc = nn.Sequential(nn.Linear(in_features=1024, out_features=512*4*4),\n",
    "        #                         nn.BatchNorm1d(num_features=512*4*4, momentum=0.9),\n",
    "        #                         nn.ReLU(True))\n",
    "        # self.fc = nn.Sequential(nn.Linear(in_features=1024, out_features=256*6*7, bias=False))\n",
    "        self.fc = nn.Sequential(nn.Linear(in_features=512, out_features=512*2*3, bias=False))\n",
    "        layers_list = []\n",
    "        # layers_list.append(nn.BatchNorm2d(256, momentum=0.9))\n",
    "        # layers_list.append(nn.ReLU(True))\n",
    "        layers_list.append(DecoderBlock(channel_in=512, channel_out=256, kernel_size=4, padding=1, stride=2)) #256*4\n",
    "        layers_list.append(DecoderBlock(channel_in=256, channel_out=256, kernel_size=4, padding=1, stride=2)) #256*8\n",
    "        # layers_list.append(DecoderBlock(channel_in=256, channel_out=256, kernel_size=4, padding=1, stride=2)) #256*16\n",
    "        # layers_list.append(DecoderBlock(channel_in=256, channel_out=256, kernel_size=3, padding=1, stride=1)) #256*16\n",
    "        # # layers_list.append(DecoderBlock(channel_in=256, channel_out=256, kernel_size=3, padding=1, stride=1, output_padding=0)) #256*12*14\n",
    "\n",
    "        self.conv = nn.Sequential(*layers_list)\n",
    "\n",
    "    def forward(self, ten):\n",
    "        # print(\"in DecoderGenerator, print some shape \")\n",
    "        # ten = self.fc(ten)\n",
    "        # ten = ten.view(ten.size()[0],512, 4, 4)\n",
    "        ten = self.fc(ten)\n",
    "        ten = ten.view(ten.size()[0],512, 2, 3)\n",
    "        ten = self.conv(ten)\n",
    "        assert ten.size()[1] == 256\n",
    "        assert ten.size()[2] == 8\n",
    "        assert ten.size()[3] == 12\n",
    "        return ten\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return super(DecoderGenerator_mask_eye, self).__call__(*args, **kwargs)\n",
    "\n",
    "\n",
    "class DecoderGenerator_mask_skin(nn.Module):\n",
    "    def __init__(self, norm_layer):  \n",
    "        super(DecoderGenerator_mask_skin, self).__init__()\n",
    "        # input is 128*4*4\n",
    "        self.fc = nn.Sequential(nn.Linear(in_features=512, out_features=512*2*2))\n",
    "        layers_list = []\n",
    "        layers_list.append(DecoderBlock(channel_in=512, channel_out=256, kernel_size=4, padding=1, stride=2))  #256*4\n",
    "        layers_list.append(DecoderBlock(channel_in=256, channel_out=256, kernel_size=4, padding=1, stride=2))  #256*8\n",
    "        layers_list.append(DecoderBlock(channel_in=256, channel_out=256, kernel_size=4, padding=1, stride=2))  #256*16\n",
    "        layers_list.append(DecoderBlock(channel_in=256, channel_out=256, kernel_size=4, padding=1, stride=2))  #256*32\n",
    "        layers_list.append(DecoderBlock(channel_in=256, channel_out=256, kernel_size=4, padding=1, stride=2))  #256*64\n",
    "        self.conv = nn.Sequential(*layers_list)\n",
    "\n",
    "    def forward(self, ten):\n",
    "        # print(\"in DecoderGenerator_mask_skin, print some shape \")\n",
    "        ten = self.fc(ten)\n",
    "        ten = ten.view(ten.size()[0],512, 2, 2)\n",
    "        ten = self.conv(ten)\n",
    "        assert ten.size()[1] == 256\n",
    "        assert ten.size()[2] == 64\n",
    "        return ten\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return super(DecoderGenerator_mask_skin, self).__call__(*args, **kwargs)\n",
    "    \n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "def get_norm_layer(norm_type='instance'):\n",
    "    if norm_type == 'batch':\n",
    "        norm_layer = functools.partial(nn.BatchNorm2d, affine=True)\n",
    "    elif norm_type == 'instance':\n",
    "        norm_layer = functools.partial(nn.InstanceNorm2d, affine=False)\n",
    "    else:\n",
    "        raise NotImplementedError('normalization layer [%s] is not found' % norm_type)\n",
    "    return norm_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FurryGan(nn.Module):\n",
    "    def __init__(self, isTrain=True):\n",
    "        \n",
    "        #Hyperparams\n",
    "        self.lr = 0.0002\n",
    "        self.beta1 = 0.5\n",
    "        \n",
    "        self.input_nc = 11             #number of input channels\n",
    "        self.output_nc = 3             #number of output channels\n",
    "        self.label_nc = 11             #number of mask channels\n",
    "        self.isTrain = isTrain         #Whether to train\n",
    "        self.dis_net_input_nc = self.input_nc + self.output_nc\n",
    "        self.dis_n_layers = 3\n",
    "        self.num_D = 2\n",
    "        self.lambda_feat= 10.0\n",
    "        \n",
    "        #Loss Function parameters - used in init_loss_funtion\n",
    "        self.use_gan_feat_loss = True\n",
    "        self.no_vgg_loss = True\n",
    "        self.no_l2_loss = True\n",
    "        \n",
    "        #Optimization Parameters\n",
    "        self.use_lsgan = False\n",
    "        \n",
    "        self.no_ganFeat_loss= True\n",
    "        \n",
    "        self.gen_net = GeneratorNetwork(self.input_nc, self.output_nc)\n",
    "        self.gen_net.apply(weights_init)\n",
    "        \n",
    "        if self.isTrain:\n",
    "            use_sigmoid = True\n",
    "            \n",
    "        self.dis_net = DiscriminatorNetwork(self.dis_net_input_nc, self.dis_n_layers, self.num_D, use_sigmoid)\n",
    "        self.dis_net.apply(weights_init)\n",
    "        \n",
    "        #Dont know why we need this???\n",
    "        self.dis_net2 = DiscriminatorNetwork(self.dis_net_input_nc, self.dis_n_layers, self.num_D, use_sigmoid)\n",
    "        self.dis_net2.apply(weights_init)\n",
    "        \n",
    "        self.p_net = PNetwork(self.label_nc, self.output_nc)\n",
    "        self.p_net.apply(weights_init)\n",
    "        #TODO\n",
    "        longSize = 256\n",
    "        n_downsample_global = 2\n",
    "        embed_feature_size = longSize//2**n_downsample_global \n",
    "\n",
    "        self.encoder_skin_net = EncoderGenerator_mask_skin(functools.partial(nn.BatchNorm2d, affine=True))\n",
    "        self.encoder_hair_net = EncoderGenerator_mask_skin(functools.partial(nn.BatchNorm2d, affine=True))\n",
    "        self.encoder_left_eye_net = EncoderGenerator_mask_eye(functools.partial(nn.BatchNorm2d, affine=True))\n",
    "        self.encoder_right_eye_net = EncoderGenerator_mask_eye(functools.partial(nn.BatchNorm2d, affine=True))\n",
    "        self.encoder_mouth_net = EncoderGenerator_mask_mouth(functools.partial(nn.BatchNorm2d, affine=True))       \n",
    "        \n",
    "        self.decoder_skin_net = DecoderGenerator_mask_skin(functools.partial(nn.BatchNorm2d, affine=True))\n",
    "        self.decoder_hair_net = DecoderGenerator_mask_skin(functools.partial(nn.BatchNorm2d, affine=True))\n",
    "        self.decoder_left_eye_net =  DecoderGenerator_mask_eye(functools.partial(nn.BatchNorm2d, affine=True))\n",
    "        self.decoder_right_eye_net = DecoderGenerator_mask_eye(functools.partial(nn.BatchNorm2d, affine=True))\n",
    "        self.decoder_mouth_net =  DecoderGenerator_mask_mouth(functools.partial(nn.BatchNorm2d, affine=True)) \n",
    "        \n",
    "        \n",
    "        self.decoder_skin_image_net = DecoderGenerator_mask_skin_image(functools.partial(nn.BatchNorm2d, affine=True))\n",
    "        self.decoder_hair_image_net = DecoderGenerator_mask_skin_image(functools.partial(nn.BatchNorm2d, affine=True))\n",
    "        self.decoder_left_eye_image_net = DecoderGenerator_mask_eye_image(norm_layer)\n",
    "        self.decoder_right_eye_image_net = DecoderGenerator_mask_eye_image(norm_layer)\n",
    "        self.decoder_mouth_image_net = DecoderGenerator_mask_mouth_image(norm_layer)\n",
    "        \n",
    "        if self.isTrain:\n",
    "            \n",
    "            self.old_lr = self.lr\n",
    "            \n",
    "            self.loss_filter = self.init_loss_filter(self.no_ganFeat_loss, self.no_vgg_loss, self.no_l2_loss)\n",
    "            \n",
    "            \n",
    "            self.criterionGAN = GANLoss(use_lsgan=self.use_lsgan, tensor=self.Tensor)   \n",
    "            self.criterionFeat = torch.nn.L1Loss()\n",
    "            self.criterionL2 = torch.nn.MSELoss()\n",
    "            self.criterionL1 = torch.nn.L1Loss()\n",
    "            self.criterionMFM = MFMLoss()\n",
    "            \n",
    "            weight_list = [0.2,1,5,5,5,5,3,8,8,8,1]\n",
    "            self.criterionCrossEntropy = torch.nn.CrossEntropyLoss(weight = torch.FloatTensor(weight_list))\n",
    "            \n",
    "            if self.no_vgg_loss:             \n",
    "                self.criterionVGG = VGGLoss(weights=None)\n",
    "                \n",
    "            self.criterionGM = GramMatrixLoss()\n",
    "            self.loss_names = self.loss_filter('KL_embed','L2_mask_image','G_GAN','G_GAN_Feat','G_VGG','D_real','D_fake','L2_image','ParsingLoss','G2_GAN','D2_real','D2_fake')\n",
    "            \n",
    "            \n",
    "            params_decoder = list(self.decoder_skin_net.parameters()) + list(self.decoder_hair_net.parameters()) + list(self.decoder_left_eye_net.parameters()) + list(self.decoder_right_eye_net.parameters()) + list(self.decoder_mouth_net.parameters())\n",
    "            params_image_decoder_params = list(self.decoder_skin_image_net.parameters()) + list(self.decoder_hair_image_net.parameters()) + list(self.decoder_left_eye_image_net.parameters()) + list(self.decoder_right_eye_image_net.parameters()) + list(self.decoder_mouth_image_net.parameters())\n",
    "            params_encoder = list(self.encoder_skin_net.parameters()) + list(self.encoder_hair_net.parameters()) + list(self.encoder_left_eye_net.parameters()) + list(self.encoder_right_eye_net.parameters()) + list(self.encoder_mouth_net.parameters())\n",
    "            \n",
    "            params_together = list(self.gen_net.parameters()) + params_decoder + params_encoder + params_image_decoder\n",
    "            self.optimizer_G_together = torch.optim.Adam(params_together, lr=self.lr, betas=(self.beta1, 0.999))\n",
    "            \n",
    "            params = list(self.dis_net.parameters())    \n",
    "            self.optimizer_D = torch.optim.Adam(params, lr=self.lr, betas=(self.beta1, 0.999))\n",
    "\n",
    "            # optimizer D2\n",
    "            params = list(self.dis_net2.parameters())    \n",
    "            self.optimizer_D2 = torch.optim.Adam(params, lr=self.lr, betas=(self.beta1, 0.999))\n",
    "                \n",
    "        \n",
    "    def init_loss_filter(self, use_gan_feat_loss, use_vgg_loss, use_l2_loss):\n",
    "        flags = (True,True,True, use_gan_feat_loss, use_vgg_loss, True, True, use_l2_loss,True,True,True,True)\n",
    "        def loss_filter(kl_loss,l2_mask_image,g_gan, g_gan_feat, g_vgg, d_real, d_fake, l2_image, loss_parsing,g2_gan,d2_real,d2_fake):\n",
    "            return [l for (l,f) in zip((kl_loss,l2_mask_image,g_gan,g_gan_feat,g_vgg,d_real,d_fake,l2_image,loss_parsing,g2_gan,d2_real,d2_fake),flags) if f]\n",
    "        \n",
    "        return loss_filter\n",
    "    \n",
    "    def encode_input(self, label_map, inst_map=None, real_image=None, feat_map=None, image_affine=None, infer=False):             \n",
    "        size = label_map.size()\n",
    "        oneHot_size = (size[0], self.label_nc, size[2], size[3])\n",
    "        input_label = torch.cuda.FloatTensor(torch.Size(oneHot_size)).zero_()\n",
    "        input_label = input_label.scatter_(1, label_map.data.long().cuda(), 1.0)\n",
    "#         if self.opt.data_type == 16:\n",
    "#             input_label = input_label.half()\n",
    "\n",
    "        # get edges from instance map\n",
    "#         if not self.opt.no_instance:\n",
    "#             inst_map = inst_map.data.cuda()\n",
    "#             edge_map = self.get_edges(inst_map)\n",
    "#             input_label = torch.cat((input_label, edge_map), dim=1) \n",
    "        input_label = Variable(input_label, volatile=infer)\n",
    "\n",
    "        # real images for training\n",
    "        if real_image is not None:\n",
    "            real_image = Variable(real_image.data.cuda())\n",
    "\n",
    "        # affine real images for training\n",
    "        if image_affine is not None:\n",
    "            image_affine = Variable(image_affine.data.cuda())\n",
    "\n",
    "        return input_label, inst_map, real_image, feat_map, image_affine\n",
    "    \n",
    "    def forward(self, bg_image, label, inst, image, feat, image_affine, mask_list, ori_label, infer=False):\n",
    "        input_label, inst_map, real_image, feat_map, real_bg_image = self.encode_input(label, inst, bg_image, feat, bg_image)\n",
    "        mask4_image = torch.zeros(label.size()[0],3,32,48).cuda()\n",
    "        mask5_image = torch.zeros(label.size()[0],3,32,48).cuda()\n",
    "        mask_mouth_image = torch.zeros(label.size()[0],3,80,144).cuda()\n",
    "        mask_mouth = torch.zeros(label.size()[0],3,80,144).cuda()\n",
    "\n",
    "\n",
    "        mask_skin = ((label==1)+(label==2)+(label==3)+(label==6)).type(torch.cuda.FloatTensor)\n",
    "        mask_skin_image = mask_skin * real_image\n",
    "\n",
    "        mask_hair = (label==10).type(torch.cuda.FloatTensor)\n",
    "        mask_hair_image = mask_hair * real_image\n",
    "\n",
    "        mask_mouth_whole = ((label==7)+(label==8)+(label==9)).type(torch.cuda.FloatTensor)\n",
    "\n",
    "        for batch_index in range(0,label.size()[0]):\n",
    "            mask4_image[batch_index] = real_image[batch_index,:,int(mask_list[batch_index][0])-16:int(mask_list[batch_index][0])+16,int(mask_list[batch_index][1])-24:int(mask_list[batch_index][1])+24]\n",
    "            mask5_image[batch_index] = real_image[batch_index,:,int(mask_list[batch_index][2])-16:int(mask_list[batch_index][2])+16,int(mask_list[batch_index][3])-24:int(mask_list[batch_index][3])+24]\n",
    "            mask_mouth_image[batch_index] = real_image[batch_index,:,int(mask_list[batch_index][4])-40:int(mask_list[batch_index][4])+40,int(mask_list[batch_index][5])-72:int(mask_list[batch_index][5])+72]\n",
    "            \n",
    "            mask_mouth[batch_index] = mask_mouth_whole[batch_index,:,int(mask_list[batch_index][4])-40:int(mask_list[batch_index][4])+40,int(mask_list[batch_index][5])-72:int(mask_list[batch_index][5])+72]\n",
    "\n",
    "        mask_mouth_image = mask_mouth * mask_mouth_image\n",
    "        \n",
    "        encode_label_feature = self.gen_net.forward(input_label,type=\"label_encoder\")\n",
    "        bg_feature = self.gen_net.forward(real_bg_image,type=\"bg_encoder\")\n",
    "        mask_bg = (label==0).type(torch.cuda.FloatTensor)\n",
    "        mask_bg_feature = mask_bg * bg_feature\n",
    "        \n",
    "        loss_mask_image = 0\n",
    "        loss_KL = 0\n",
    "        \n",
    "        mus4, log_variances4 = self.encoder_left_eye_net(mask4_image)\n",
    "        variances4 = torch.exp(log_variances4 * 0.5)\n",
    "        random_sample4 = Variable(torch.randn(mus4.size()).cuda(), requires_grad=True)\n",
    "        correct_sample4 = random_sample4 * variances4 + mus4\n",
    "        loss_KL4 = -0.5*torch.sum(-log_variances4.exp() - torch.pow(mus4,2) + log_variances4 + 1)\n",
    "        reconstruce_mask4_image = self.decoder_left_eye_image_net(correct_sample4)\n",
    "        loss_mask_image += self.criterionL2(reconstruce_mask4_image, mask4_image.detach()) * 10 \n",
    "        loss_KL += loss_KL4\n",
    "        decode_embed_feature4 = self.decoder_left_eye_net(correct_sample4)\n",
    "        \n",
    "        mus5, log_variances5 = self.encoder_right_eye_net(mask5_image)\n",
    "        variances5 = torch.exp(log_variances5 * 0.5)\n",
    "        random_sample5 = Variable(torch.randn(mus5.size()).cuda(), requires_grad=True)\n",
    "        correct_sample5 = random_sample5 * variances5 + mus5\n",
    "        loss_KL5 = -0.5*torch.sum(-log_variances5.exp() - torch.pow(mus5,2) + log_variances5 + 1)\n",
    "        reconstruce_mask5_image = self.decoder_right_eye_image_net(correct_sample5)\n",
    "        loss_mask_image += self.criterionL2(reconstruce_mask5_image, mask5_image.detach()) * 10 \n",
    "        loss_KL += loss_KL5\n",
    "        decode_embed_feature5 = self.decoder_right_eye_net(correct_sample5)\n",
    "        \n",
    "        mus_skin, log_variances_skin = self.encoder_skin_net(mask_skin_image)\n",
    "        variances_skin = torch.exp(log_variances_skin * 0.5)\n",
    "        random_sample_skin = Variable(torch.randn(mus_skin.size()).cuda(), requires_grad=True)\n",
    "        correct_sample_skin = random_sample_skin * variances_skin + mus_skin\n",
    "        loss_KL_skin = -0.5*torch.sum(-log_variances_skin.exp() - torch.pow(mus_skin,2) + log_variances_skin + 1)\n",
    "        reconstruce_mask_skin_image = self.decoder_skin_image_net(correct_sample_skin)\n",
    "        reconstruce_mask_skin_image = mask_skin * reconstruce_mask_skin_image\n",
    "        loss_mask_image += self.criterionL2(reconstruce_mask_skin_image, mask_skin_image.detach()) * 10 \n",
    "        loss_KL += loss_KL_skin\n",
    "        decode_embed_feature_skin = self.decoder_skin_net(correct_sample_skin)\n",
    "        \n",
    "        mus_hair, log_variances_hair = self.encoder_hair_net(mask_hair_image)\n",
    "        variances_hair = torch.exp(log_variances_hair * 0.5)\n",
    "        random_sample_hair = Variable(torch.randn(mus_hair.size()).cuda(), requires_grad=True)\n",
    "        correct_sample_hair = random_sample_hair * variances_hair + mus_hair\n",
    "        loss_KL_hair = -0.5*torch.sum(-log_variances_hair.exp() - torch.pow(mus_hair,2) + log_variances_hair + 1)\n",
    "        reconstruce_mask_hair_image = self.decoder_hair_image_net(correct_sample_hair)\n",
    "        reconstruce_mask_hair_image = mask_hair * reconstruce_mask_hair_image\n",
    "        loss_mask_image += self.criterionL2(reconstruce_mask_hair_image, mask_hair_image.detach()) * 10 \n",
    "        loss_KL += loss_KL_hair\n",
    "        decode_embed_feature_hair = self.decoder_hair_net(correct_sample_hair)\n",
    "        \n",
    "        mus_mouth, log_variances_mouth = self.encoder_mouth_net(mask_mouth_image)\n",
    "        variances_mouth = torch.exp(log_variances_mouth * 0.5)\n",
    "        random_sample_mouth = Variable(torch.randn(mus_mouth.size()).cuda(), requires_grad=True)\n",
    "        correct_sample_mouth = random_sample_mouth * variances_mouth + mus_mouth\n",
    "        loss_KL_mouth = -0.5*torch.sum(-log_variances_mouth.exp() - torch.pow(mus_mouth,2) + log_variances_mouth + 1)\n",
    "        reconstruce_mask_mouth_image = self.decoder_mouth_image_net(correct_sample_mouth)\n",
    "        reconstruce_mask_mouth_image = mask_mouth * reconstruce_mask_mouth_image \n",
    "        loss_mask_image += self.criterionL2(reconstruce_mask_mouth_image, mask_mouth_image.detach()) * 10 \n",
    "        loss_KL += loss_KL_mouth\n",
    "        decode_embed_feature_mouth = self.decoder_mouth_net(correct_sample_mouth)\n",
    "        \n",
    "        \n",
    "        left_eye_tensor = torch.zeros(encode_label_feature.size()).cuda()\n",
    "        right_eye_tensor = torch.zeros(encode_label_feature.size()).cuda()\n",
    "        mouth_tensor = torch.zeros(encode_label_feature.size()).cuda()\n",
    "\n",
    "        reorder_left_eye_tensor = torch.zeros(encode_label_feature.size()).cuda()\n",
    "        reorder_right_eye_tensor = torch.zeros(encode_label_feature.size()).cuda()\n",
    "        reorder_mouth_tensor = torch.zeros(encode_label_feature.size()).cuda()\n",
    "\n",
    "        new_order = torch.randperm(label.size()[0])\n",
    "        \n",
    "        reorder_decode_embed_feature4 = decode_embed_feature4[new_order]\n",
    "        reorder_decode_embed_feature5 = decode_embed_feature5[new_order]\n",
    "        reorder_decode_embed_feature_mouth = decode_embed_feature_mouth[new_order]\n",
    "        reorder_decode_embed_feature_skin = decode_embed_feature_skin[new_order]\n",
    "        reorder_decode_embed_feature_hair = decode_embed_feature_hair[new_order]\n",
    "        \n",
    "        for batch_index in range(0,label.size()[0]):\n",
    "            try:\n",
    "                reorder_left_eye_tensor[batch_index,:,int(mask_list[batch_index][0]/4+0.5)-4:int(mask_list[batch_index][0]/4+0.5)+4,int(mask_list[batch_index][1]/4+0.5)-6:int(mask_list[batch_index][1]/4+0.5)+6] += reorder_decode_embed_feature4[batch_index]\n",
    "                reorder_right_eye_tensor[batch_index,:,int(mask_list[batch_index][2]/4+0.5)-4:int(mask_list[batch_index][2]/4+0.5)+4,int(mask_list[batch_index][3]/4+0.5)-6:int(mask_list[batch_index][3]/4+0.5)+6] += reorder_decode_embed_feature5[batch_index]\n",
    "                reorder_mouth_tensor[batch_index,:,int(mask_list[batch_index][4]/4+0.5)-10:int(mask_list[batch_index][4]/4+0.5)+10,int(mask_list[batch_index][5]/4+0.5)-18:int(mask_list[batch_index][5]/4+0.5)+18] += reorder_decode_embed_feature_mouth[batch_index]\n",
    "            except:\n",
    "                print(\"wrong0 ! \")\n",
    "                \n",
    "                \n",
    "        reconstruct_transfer_face = self.gen_net.forward(torch.cat((encode_label_feature,reorder_left_eye_tensor,reorder_right_eye_tensor,reorder_decode_embed_feature_skin,reorder_decode_embed_feature_hair,reorder_mouth_tensor),1),type=\"image_G\")\n",
    "        reconstruct_transfer_image = self.gen_net.forward(torch.cat((reconstruct_transfer_face,mask_bg_feature),1),type=\"bg_decoder\")\n",
    "        \n",
    "        parsing_label_feature = self.p_net(reconstruct_transfer_image)\n",
    "        parsing_label = softmax2label(parsing_label_feature)\n",
    "        gt_label = torch.squeeze(ori_label.type(torch.cuda.LongTensor),1)\n",
    "        loss_parsing = self.criterionCrossEntropy(parsing_label_feature,gt_label)*self.opt.lambda_feat\n",
    "        \n",
    "        pred_fake2_pool = self.dis_net2.forward(torch.cat((input_label, reconstruct_transfer_image.detach()), dim=1))\n",
    "        loss_D2_fake = self.criterionGAN(pred_fake2_pool, False)\n",
    "        # Real Detection and Loss\n",
    "        # pred_real = self.discriminate(input_label, real_image)\n",
    "        pred_real2 = self.dis_net2.forward(torch.cat((input_label, real_image.detach()), dim=1))\n",
    "        loss_D2_real = self.criterionGAN(pred_real2, True)\n",
    "        # GAN loss (Fake Passability Loss)        \n",
    "        pred_fake2 = self.dis_net2.forward(torch.cat((input_label, reconstruct_transfer_image), dim=1))        \n",
    "        loss_G2_GAN = self.criterionGAN(pred_fake2, True)\n",
    "        \n",
    "        \n",
    "        for batch_index in range(0,label.size()[0]):\n",
    "            try:\n",
    "                left_eye_tensor[batch_index,:,int(mask_list[batch_index][0]/4+0.5)-4:int(mask_list[batch_index][0]/4+0.5)+4,int(mask_list[batch_index][1]/4+0.5)-6:int(mask_list[batch_index][1]/4+0.5)+6] += decode_embed_feature4[batch_index]\n",
    "                right_eye_tensor[batch_index,:,int(mask_list[batch_index][2]/4+0.5)-4:int(mask_list[batch_index][2]/4+0.5)+4,int(mask_list[batch_index][3]/4+0.5)-6:int(mask_list[batch_index][3]/4+0.5)+6] += decode_embed_feature5[batch_index]\n",
    "                mouth_tensor[batch_index,:,int(mask_list[batch_index][4]/4+0.5)-10:int(mask_list[batch_index][4]/4+0.5)+10,int(mask_list[batch_index][5]/4+0.5)-18:int(mask_list[batch_index][5]/4+0.5)+18] += decode_embed_feature_mouth[batch_index]\n",
    "            except:\n",
    "                print(\"wrong ! \")\n",
    "\n",
    "        reconstruct_face = self.gen_net.forward(torch.cat((encode_label_feature,left_eye_tensor,right_eye_tensor,decode_embed_feature_skin,decode_embed_feature_hair,mouth_tensor),1),type=\"image_G\")\n",
    "\n",
    "        reconstruct_image = self.gen_net.forward(torch.cat((reconstruct_face,mask_bg_feature),1),type=\"bg_decoder\")        \n",
    "\n",
    "\n",
    "        # reconstruce_part image\n",
    "\n",
    "        mask_left_eye = (label==4).type(torch.cuda.FloatTensor)\n",
    "        mask_right_eye = (label==5).type(torch.cuda.FloatTensor)\n",
    "        mask_mouth = ((label==7)+(label==8)+(label==9)).type(torch.cuda.FloatTensor)\n",
    "\n",
    "        loss_L2_image = 0\n",
    "        for batch_index in range(0,label.size()[0]):\n",
    "            loss_L2_image += self.criterionL2( mask_left_eye*reconstruct_image, mask_left_eye*real_image) * 10 \n",
    "            loss_L2_image += self.criterionL2( mask_right_eye*reconstruct_image, mask_right_eye*real_image) * 10 \n",
    "            loss_L2_image += self.criterionL2( mask_skin*reconstruct_image, mask_skin*real_image) * 5 \n",
    "            loss_L2_image += self.criterionL2( mask_hair*reconstruct_image, mask_hair*real_image) * 5\n",
    "            loss_L2_image += self.criterionL2( mask_mouth*reconstruct_image, mask_mouth*real_image) * 10 \n",
    "            loss_L2_image += self.criterionL2( reconstruct_image, real_bg_image ) * 10\n",
    "\n",
    "        # Fake Detection and Loss\n",
    "        # pred_fake_pool = self.discriminate(input_label, reconstruct_image, use_pool=True)\n",
    "        pred_fake_pool = self.dis_net.forward(torch.cat((input_label, reconstruct_image.detach()), dim=1))\n",
    "        loss_D_fake = self.criterionGAN(pred_fake_pool, False)\n",
    "        # Real Detection and Loss\n",
    "        # pred_real = self.discriminate(input_label, real_image)\n",
    "        pred_real = self.dis_net.forward(torch.cat((input_label, real_image.detach()), dim=1))\n",
    "        loss_D_real = self.criterionGAN(pred_real, True)\n",
    "        # GAN loss (Fake Passability Loss)        \n",
    "        pred_fake = self.dis_net.forward(torch.cat((input_label, reconstruct_image), dim=1))        \n",
    "        loss_G_GAN = self.criterionGAN(pred_fake, True)\n",
    "        \n",
    "        \n",
    "        loss_G_GAN_Feat = 0\n",
    "        if self.no_ganFeat_loss:\n",
    "            feat_weights = 4.0 / (self.dis_n_layers + 1)\n",
    "            D_weights = 1.0 / self.num_D\n",
    "            for i in range(self.num_D):\n",
    "                for j in range(len(pred_fake[i])-1):\n",
    "                    loss_G_GAN_Feat += D_weights * feat_weights * \\\n",
    "                        self.criterionFeat(pred_fake[i][j], pred_real[i][j].detach()) * self.lambda_feat\n",
    "        \n",
    "        all_mask_tensor = torch.cat((mask_left_eye,mask_right_eye,mask_skin,mask_hair,mask_mouth),1)\n",
    "        \n",
    "        mask_weight_list = [10,10,5,5,10]\n",
    "        # VGG feature matching loss\n",
    "        loss_G_VGG = 0\n",
    "        if self.no_vgg_loss:\n",
    "            loss_G_VGG += self.criterionVGG(reconstruct_image, real_image, all_mask_tensor, mask_weights = mask_weight_list) * self.opt.lambda_feat * 3\n",
    "            # loss_G_VGG += self.criterionVGG(reconstruct_image, real_image, mask4, weights = [1.0/4,1.0/4,1.0/4,1.0/8,1.0/8]) * self.opt.lambda_feat * 10\n",
    "            \n",
    "        return self.loss_filter( loss_KL,loss_mask_image,loss_G_GAN, loss_G_GAN_Feat, loss_G_VGG, loss_D_real, loss_D_fake, loss_L2_image, loss_parsing, loss_G2_GAN, loss_D2_real, loss_D2_fake), None if not infer else reconstruct_image, None if not infer else reconstruce_mask4_image, None if not infer else reconstruce_mask5_image, None if not infer else reconstruce_mask_skin_image, None if not infer else reconstruce_mask_hair_image, None if not infer else reconstruce_mask_mouth_image, None if not infer else reconstruct_transfer_image, None if not infer else parsing_label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
