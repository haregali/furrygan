{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-cae91ec01317>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-cae91ec01317>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    class FurryGan(nn.Module)L\u001b[0m\n\u001b[1;37m                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class GeneratorNetwork(nn.Module):\n",
    "    def __init__(self, input_nc, self.output_nc, self.ngf):\n",
    "        self.input_nc = input_nc\n",
    "        self.output_nc = output_nc\n",
    "        self.ngf = 64\n",
    "        self.norm_type = 'batch'\n",
    "        self.n_downsample = 2\n",
    "        self.n_blocks_global = 9\n",
    "        self.n_local_enhancers = 1\n",
    "        self.n_blocks_local = 3\n",
    "        self.embed_nc = 256*5\n",
    "        self.padding_type='reflect'\n",
    "\n",
    "        super(EmbedGlobalBGGenerator, self).__init__()\n",
    "        norm_layer = get_norm_layer(norm_type=self.norm_type)\n",
    "        activation = nn.ReLU(True)\n",
    "        \n",
    "        downsample_model = [nn.ReflectionPad2d(3), nn.Conv2d(self.input_nc, self.ngf, kernel_size=7, padding=0), norm_layer(self.ngf), activation]\n",
    "        \n",
    "        for i in range(self.n_downsample):\n",
    "            mult = 2**i\n",
    "            if i != self.n_downsample-1:\n",
    "                downsample_model += [nn.Conv2d(self.ngf * mult, self.ngf * mult * 2, kernel_size=3, stride=2, padding=1),\n",
    "                      norm_layer(self.ngf * mult * 2), activation]\n",
    "            else:\n",
    "                downsample_model += [nn.Conv2d(self.ngf * mult, self.ngf * mult * 2, kernel_size=3, stride=2, padding=1),\n",
    "                      norm_layer(self.ngf * mult * 2), activation]\n",
    "        self.downsample_model = nn.Sequential(*downsample_model)\n",
    "        \n",
    "        model=[]\n",
    "        model += [nn.Conv2d(in_channels=self.ngf*(2**self.n_downsample)+self.embed_nc, out_channels=self.ngf*(2**self.n_downsample), kernel_size=1, padding=0, stride=1, bias=True)]\n",
    "\n",
    "        mult = 2**self.n_downsample\n",
    "        for i in range(self.n_blocks_global):\n",
    "            model += [ResnetBlock(self.ngf * mult, padding_type=self.padding_type='reflect', activation=activation, norm_layer=norm_layer)]\n",
    "        \n",
    "        ### upsample         \n",
    "        for i in range(self.n_downsample):\n",
    "            mult = 2**(self.n_downsample - i)\n",
    "            model += [nn.ConvTranspose2d(self.ngf * mult, int(self.ngf * mult / 2), kernel_size=4, stride=2, padding=1, output_padding=0),\n",
    "                       norm_layer(int(self.ngf * mult / 2)), activation]\n",
    "        \n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "        bg_encoder = [nn.ReflectionPad2d(3), nn.Conv2d(3, self.ngf, kernel_size=7, padding=0), norm_layer(self.ngf), activation]\n",
    "        self.bg_encoder = nn.Sequential(*bg_encoder)\n",
    "\n",
    "        bg_decoder = [nn.Conv2d(in_channels=ngf*2, out_channels=self.ngf, kernel_size=1, padding=0, stride=1, bias=True)]\n",
    "        bg_decoder += [nn.ReflectionPad2d(3), nn.Conv2d(self.ngf, output_nc, kernel_size=7, padding=0), nn.Tanh()]\n",
    "        self.bg_decoder = nn.Sequential(*bg_decoder)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "\n",
    "    \n",
    "class DiscriminatorNetwork(nn.Module):\n",
    "    def __init__(self, input_nc, dis_n_layers, use_sigmoid):\n",
    "        self.input_nc = input_nc\n",
    "        self.dis_n_layers = dis_n_layers\n",
    "        self.use_sigmoid = use_sigmoid\n",
    "        self.ndf = 64\n",
    "        self.norm_type = 'batch'\n",
    "        self.num_D = 2\n",
    "        self.getIntermFeat = True\n",
    "        \n",
    "        super(DiscriminatorNetwork, self).__init__()\n",
    "        \n",
    "        norm_layer = get_norm_layer(norm_type=self.norm_type)\n",
    " \n",
    "        for i in range(self.num_D):\n",
    "            netD = NLayerDiscriminator(self.input_nc, self.ndf, self.dis_n_layers, norm_layer, use_sigmoid, getIntermFeat)\n",
    "            if getIntermFeat:                                \n",
    "                for j in range(n_layers+2):\n",
    "                    setattr(self, 'scale'+str(i)+'_layer'+str(j), getattr(netD, 'model'+str(j)))                                   \n",
    "            else:\n",
    "                setattr(self, 'layer'+str(i), netD.model)\n",
    "\n",
    "        self.downsample = nn.AvgPool2d(3, stride=2, padding=[1, 1], count_include_pad=False)\n",
    "        \n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "def get_norm_layer(norm_type='instance'):\n",
    "    if norm_type == 'batch':\n",
    "        norm_layer = functools.partial(nn.BatchNorm2d, affine=True)\n",
    "    elif norm_type == 'instance':\n",
    "        norm_layer = functools.partial(nn.InstanceNorm2d, affine=False)\n",
    "    else:\n",
    "        raise NotImplementedError('normalization layer [%s] is not found' % norm_type)\n",
    "    return norm_layer\n",
    "\n",
    "        \n",
    "class FurryGan(nn.Module):\n",
    "    def __init__(self, isTrain=True):\n",
    "        self.input_nc = 11             #number of input channels\n",
    "        self.output_nc = 3             #number of output channels\n",
    "        self.isTrain = isTrain         #Whether to train\n",
    "        self.dis_net_input_nc = self.input_nc + self.output_nc\n",
    "        self.dis_n_layers = 3\n",
    "        \n",
    "        self.gen_net = GeneratorNetwork(self.input_nc, self.output_nc)\n",
    "        self.gen_net.apply(weights_init)\n",
    "        \n",
    "        if self.isTrain:\n",
    "            use_sigmoid = True\n",
    "            \n",
    "        \n",
    "        self.dis_net = DiscriminatorNetwork(self.dis_net_input_nc, self.dis_n_layers, use_sigmoid)\n",
    "        \n",
    "        #TODO\n",
    "#         embed_feature_size\n",
    "\n",
    "        self.encoder_skin_net = \n",
    "        self.encoder_skin_hair = \n",
    "        self.encoder_skin_left_eye = \n",
    "        self.encoder_skin_right_eye = \n",
    "        self.encoder_skin_mouth = \n",
    "        \n",
    "        \n",
    "        self.decoder_skin_net = \n",
    "        self.decoder_skin_hair = \n",
    "        self.decoder_skin_left_eye = \n",
    "        self.decoder_skin_right_eye = \n",
    "        self.decoder_skin_mouth = \n",
    "        \n",
    "        \n",
    "        self.decoder_skin_image_net = \n",
    "        self.decoder_skin_image_hair = \n",
    "        self.decoder_skin_image_left_eye = \n",
    "        self.decoder_skin_image_right_eye = \n",
    "        self.decoder_skin_image_mouth = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
